"""
WMS QA Dataset V2 - ëŒ€ê·œëª¨ ìƒì„± (50K samples)
- expanded_data/ ë””ë ‰í† ë¦¬ì—ì„œ personas & topics ë™ì  ë¡œë“œ
- ë°°ì¹˜ ì²˜ë¦¬ + ì²´í¬í¬ì¸íŠ¸
- vLLM ê¸°ë°˜ ê³ ì† ìƒì„±
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import gc
import torch

# conv_gen ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))


class QADatasetGeneratorV2:
    """ëŒ€ê·œëª¨ QA ë°ì´í„°ì…‹ ìƒì„±ê¸°"""
    
    def __init__(
        self,
        expanded_data_dir: str = "expanded_data",
        output_dir: str = "output",
        use_vllm: bool = True
    ):
        self.expanded_data_dir = Path(expanded_data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        self.use_vllm = use_vllm
        
        print("\n" + "="*80)
        print("QA Dataset Generator V2 ì´ˆê¸°í™”")
        print(f"Mode: {'vLLM (High-Speed)' if use_vllm else 'Transformers'}")
        print("="*80 + "\n")
        
        # Personas & Topics ë¡œë“œ
        self.personas = self._load_personas()
        self.topics_technical = self._load_topics("technical")
        self.topics_practical = self._load_topics("practical")
        self.all_topics = self.topics_technical + self.topics_practical
        
        print(f"âœ“ Personas ë¡œë“œ: {len(self.personas)}ê°œ")
        print(f"âœ“ Technical Topics: {len(self.topics_technical)}ê°œ")
        print(f"âœ“ Practical Topics: {len(self.topics_practical)}ê°œ")
        print(f"âœ“ ì´ Topics: {len(self.all_topics)}ê°œ\n")
        
        # Answer Maker ì´ˆê¸°í™” (vLLM)
        if self.use_vllm:
            from conv_gen.a_maker_vl import AnswerMakerVLLM
            self.answer_maker = AnswerMakerVLLM()
        else:
            raise NotImplementedError("V2ëŠ” vLLM ì „ìš©ì…ë‹ˆë‹¤. use_vllm=Trueë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    
    def _load_personas(self) -> List[Dict]:
        """Personas ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ë³‘í•©)"""
        personas = []
        persona_files = sorted(self.expanded_data_dir.glob("personas_*.json"))
        
        for file in persona_files:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì§ì ‘ ì €ì¥ë˜ì–´ ìˆìŒ
                if isinstance(data, list):
                    personas.extend(data)
                else:
                    # í˜¹ì‹œ ë‹¤ë¥¸ í˜•ì‹ì´ë©´
                    personas.append(data)
        
        return personas
    
    def _load_topics(self, topic_type: str) -> List[str]:
        """Topics ë¡œë“œ (technical ë˜ëŠ” practical)"""
        topics = []
        topic_files = sorted(self.expanded_data_dir.glob(f"topics_*_{topic_type}.json"))
        
        for file in topic_files:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # topics í‚¤ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ
                if 'topics' in data:
                    topics.extend(data['topics'])
                elif isinstance(data, list):
                    topics.extend(data)
        
        return topics
    
    def generate_questions_for_batch(
        self,
        batch_personas: List[Dict],
        batch_topics: List[str],
        questions_per_combo: int = 1
    ) -> List[Dict]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì§ˆë¬¸ ìƒì„± (EXAONE)"""
        from conv_gen.q_gen import ExaoneQuestionMaker
        
        # Question Maker ì´ˆê¸°í™”
        q_gen = ExaoneQuestionMaker()
        
        questions_data = []
        
        # ê° í˜ë¥´ì†Œë‚˜ Ã— í† í”½ ì¡°í•©ë³„ë¡œ ì§ˆë¬¸ ìƒì„±
        for persona in batch_personas:
            for topic in batch_topics:
                # EXAONEìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
                questions = q_gen.generate_diverse_questions(
                    topics=[topic],
                    personas=[persona],
                    questions_per_topic=questions_per_combo
                )
                questions_data.extend(questions)
        
        # Question Maker ì •ë¦¬
        q_gen.cleanup()
        del q_gen
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return questions_data
    
    def generate_batch(
        self,
        batch_personas: List[Dict],
        batch_topics: List[str],
        questions_per_combo: int = 1,
        batch_id: int = 0
    ) -> List[Dict]:
        """ë°°ì¹˜ ë‹¨ìœ„ QA ìƒì„±"""
        print(f"\n{'='*80}")
        print(f"Batch {batch_id}: {len(batch_personas)} personas Ã— {len(batch_topics)} topics")
        print(f"{'='*80}\n")
        
        # STEP 1: ì§ˆë¬¸ ìƒì„±
        print(f"[1/2] ì§ˆë¬¸ ìƒì„± ì¤‘...")
        questions_data = self.generate_questions_for_batch(
            batch_personas,
            batch_topics,
            questions_per_combo
        )
        questions = [q['question'] for q in questions_data]
        print(f"âœ“ {len(questions)}ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n")
        
        # STEP 2: ë‹µë³€ ìƒì„± (vLLM)
        print(f"[2/2] ë‹µë³€ ìƒì„± ì¤‘ (vLLM + FAISS RAG)...")
        answers = self.answer_maker.generate_answers_batch(questions)
        print(f"âœ“ {len(answers)}ê°œ ë‹µë³€ ìƒì„± ì™„ë£Œ\n")
        
        # STEP 3: QA í˜ì–´ ì¡°í•©
        qa_dataset = []
        for i, (q_data, a_data) in enumerate(zip(questions_data, answers), 1):
            qa_dataset.append({
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ë¬¼ë¥˜ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. WMS ë„ì…ê³¼ ìš´ì˜ì— ëŒ€í•´ ì‹¤ë¬´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.'
                    },
                    {
                        'role': 'user',
                        'content': q_data['question']
                    },
                    {
                        'role': 'assistant',
                        'content': a_data['answer']
                    }
                ],
                'metadata': {
                    'batch_id': batch_id,
                    'topic': q_data.get('topic', 'unknown'),
                    'persona': q_data.get('persona', {}).get('name', 'unknown'),
                    'question_style': q_data.get('persona', {}).get('question_style', ''),
                    'inference_time': a_data.get('inference_time', 0),
                    'context_used': len(a_data.get('contexts', []))
                }
            })
        
        return qa_dataset
    
    def generate_large_dataset(
        self,
        total_samples: int = 50000,
        batch_size: int = 100,
        checkpoint_every: int = 1000,
        questions_per_combo: int = 1
    ):
        """ëŒ€ê·œëª¨ QA ë°ì´í„°ì…‹ ìƒì„±"""
        print("\n" + "="*80)
        print(f"ëŒ€ê·œëª¨ QA ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
        print(f"ëª©í‘œ: {total_samples:,} ìƒ˜í”Œ")
        print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"ì²´í¬í¬ì¸íŠ¸: ë§¤ {checkpoint_every} ìƒ˜í”Œ")
        print("="*80 + "\n")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        all_qa_data = []
        batch_count = 0
        
        # ì´ í•„ìš”í•œ ì¡°í•© ìˆ˜ ê³„ì‚°
        needed_combos = total_samples // questions_per_combo
        
        import itertools
        import random
        
        # Persona Ã— Topic ì¡°í•© ìƒì„±
        all_combos = list(itertools.product(self.personas, self.all_topics))
        random.shuffle(all_combos)  # ëœë¤í™”
        
        print(f"âœ“ ê°€ëŠ¥í•œ ì¡°í•© ìˆ˜: {len(all_combos):,}ê°œ")
        print(f"âœ“ í•„ìš”í•œ ì¡°í•© ìˆ˜: {needed_combos:,}ê°œ\n")
        
        # ì¡°í•©ì´ ë¶€ì¡±í•˜ë©´ ë°˜ë³µ
        if len(all_combos) < needed_combos:
            repeat_times = (needed_combos // len(all_combos)) + 1
            all_combos = all_combos * repeat_times
            random.shuffle(all_combos)
            print(f"âœ“ ì¡°í•© ë°˜ë³µ ({repeat_times}íšŒ) â†’ {len(all_combos):,}ê°œ\n")
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìƒì„±
        for i in range(0, needed_combos, batch_size):
            batch_combos = all_combos[i:i+batch_size]
            batch_personas = [combo[0] for combo in batch_combos]
            batch_topics = [combo[1] for combo in batch_combos]
            
            batch_count += 1
            
            # ë°°ì¹˜ ìƒì„±
            batch_qa = self.generate_batch(
                batch_personas,
                batch_topics,
                questions_per_combo,
                batch_id=batch_count
            )
            
            all_qa_data.extend(batch_qa)
            
            print(f"âœ“ í˜„ì¬ê¹Œì§€ ìƒì„±: {len(all_qa_data):,} / {total_samples:,} ìƒ˜í”Œ")
            print(f"  ì§„í–‰ë¥ : {len(all_qa_data)/total_samples*100:.1f}%\n")
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if len(all_qa_data) % checkpoint_every < batch_size:
                checkpoint_file = self.output_dir / f"checkpoint_{len(all_qa_data)}_{timestamp}.json"
                with open(checkpoint_file, 'w', encoding='utf-8') as f:
                    json.dump(all_qa_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_file}\n")
            
            # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
            if len(all_qa_data) >= total_samples:
                break
        
        # ìµœì¢… ì €ì¥
        final_file = self.output_dir / f"wms_qa_dataset_v2_{total_samples}_{timestamp}.json"
        with open(final_file, 'w', encoding='utf-8') as f:
            json.dump(all_qa_data[:total_samples], f, ensure_ascii=False, indent=2)
        
        print("\n" + "="*80)
        print(f"âœ“ ìƒì„± ì™„ë£Œ: {len(all_qa_data[:total_samples]):,} ìƒ˜í”Œ")
        print(f"âœ“ ì €ì¥ ìœ„ì¹˜: {final_file}")
        print("="*80 + "\n")
        
        # í†µê³„ ì¶œë ¥
        self._print_statistics(all_qa_data[:total_samples])
        
        return all_qa_data[:total_samples]
    
    def _print_statistics(self, qa_data: List[Dict]):
        """ìƒì„±ëœ ë°ì´í„° í†µê³„"""
        print("\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
        print(f"  ì´ ìƒ˜í”Œ ìˆ˜: {len(qa_data):,}")
        
        # í‰ê·  inference time
        total_time = sum(qa['metadata']['inference_time'] for qa in qa_data)
        avg_time = total_time / len(qa_data) if qa_data else 0
        print(f"  í‰ê·  Inference Time: {avg_time:.2f}ì´ˆ")
        print(f"  ì´ ìƒì„± ì‹œê°„: {total_time/60:.1f}ë¶„")
        
        # í† í”½ ë¶„í¬
        from collections import Counter
        topics = [qa['metadata']['topic'] for qa in qa_data]
        top_topics = Counter(topics).most_common(5)
        print(f"\n  ìƒìœ„ 5 í† í”½:")
        for topic, count in top_topics:
            print(f"    - {topic[:50]}...: {count}ê°œ")
        
        # í‰ê·  ë‹µë³€ ê¸¸ì´
        answer_lengths = [len(qa['messages'][2]['content']) for qa in qa_data]
        avg_length = sum(answer_lengths) / len(answer_lengths) if answer_lengths else 0
        print(f"\n  í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_length:.0f} ì")


def main():
    parser = argparse.ArgumentParser(description='WMS QA Dataset V2 Generator')
    parser.add_argument('--expanded-data-dir', type=str, default='expanded_data',
                        help='Personas & Topics ë””ë ‰í† ë¦¬')
    parser.add_argument('--output-dir', type=str, default='output',
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--total-samples', type=int, default=50000,
                        help='ìƒì„±í•  ì´ ìƒ˜í”Œ ìˆ˜')
    parser.add_argument('--batch-size', type=int, default=100,
                        help='ë°°ì¹˜ë‹¹ ìƒì„± ê°œìˆ˜')
    parser.add_argument('--checkpoint-every', type=int, default=1000,
                        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸°')
    parser.add_argument('--questions-per-combo', type=int, default=1,
                        help='PersonaÃ—Topic ì¡°í•©ë‹¹ ì§ˆë¬¸ ìˆ˜')
    
    args = parser.parse_args()
    
    # Generator ì´ˆê¸°í™”
    generator = QADatasetGeneratorV2(
        expanded_data_dir=args.expanded_data_dir,
        output_dir=args.output_dir,
        use_vllm=True
    )
    
    # ëŒ€ê·œëª¨ ìƒì„± ì‹¤í–‰
    generator.generate_large_dataset(
        total_samples=args.total_samples,
        batch_size=args.batch_size,
        checkpoint_every=args.checkpoint_every,
        questions_per_combo=args.questions_per_combo
    )


if __name__ == "__main__":
    main()

