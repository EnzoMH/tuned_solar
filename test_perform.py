#!/usr/bin/env python3
"""
EEVE Checkpoint ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ë°˜ë§â†’ì¡´ëŒ“ë§ ë³€í™˜ í™•ì¸
- ì¼ë°˜ í•œêµ­ì–´ ì§ˆë¬¸ ë‹µë³€ í’ˆì§ˆ ì²´í¬
- ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
"""

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from peft import PeftModel
from datetime import datetime
import json

class CheckpointTester:
    """ì²´í¬í¬ì¸íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def __init__(
        self,
        base_model_path: str = "yanolja/EEVE-Korean-Instruct-10.8B-v1.0",
        checkpoint_path: str = "/home/work/eeve-korean-output/checkpoint-500",  # TODO: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸
        use_4bit: bool = True
    ):
        self.base_model_path = base_model_path
        self.checkpoint_path = checkpoint_path
        
        print("\n" + "="*80)
        print(f" EEVE Checkpoint ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("="*80)
        print(f"ë² ì´ìŠ¤ ëª¨ë¸: {base_model_path}")
        print(f"ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80 + "\n")
        
        self._load_model(use_4bit)
        
    def _load_model(self, use_4bit: bool):
        """ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...\n")
        
        if use_4bit:
            bnb_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_compute_dtype=torch.bfloat16,
                bnb_4bit_use_double_quant=True
            )
            
            self.model = AutoModelForCausalLM.from_pretrained(
                self.base_model_path,
                quantization_config=bnb_config,
                device_map="auto",
                trust_remote_code=True,
                torch_dtype=torch.bfloat16
            )
        else:
            self.model = AutoModelForCausalLM.from_pretrained(
                self.base_model_path,
                device_map="auto",
                trust_remote_code=True,
                torch_dtype=torch.bfloat16
            )
        
        print("   âœ“ ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # LoRA ì–´ëŒ‘í„° ë¡œë“œ
        self.model = PeftModel.from_pretrained(
            self.model,
            self.checkpoint_path,
            is_trainable=False
        )
        
        print("   âœ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
        
        # í† í¬ë‚˜ì´ì €
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.checkpoint_path,
            trust_remote_code=True
        )
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        self.model.eval()
        print("   âœ“ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n")
    
    def generate(
        self,
        user_input: str,
        max_tokens: int = 300,
        temperature: float = 0.7,
        top_p: float = 0.9,
        top_k: int = 50,
        repetition_penalty: float = 1.1
    ) -> str:
        """ë‹µë³€ ìƒì„± (EEVE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)"""
        
        # EEVE ê³µì‹ í”„ë¡¬í”„íŠ¸
        prompt = f"""A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.
Human: {user_input}
Assistant: """
        
        inputs = self.tokenizer(
            prompt,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=4096
        )
        
        input_length = inputs.input_ids.shape[1]
        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                repetition_penalty=repetition_penalty,
                do_sample=True if temperature > 0 else False,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(
            outputs[0][input_length:],
            skip_special_tokens=True
        ).strip()
        
        return response
    
    def test_banmal_to_jondaemal(self):
        """ë°˜ë§â†’ì¡´ëŒ“ë§ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        print("ğŸ“ í…ŒìŠ¤íŠ¸ 1: ë°˜ë§ â†’ ì¡´ëŒ“ë§ ë³€í™˜")
        print("-" * 80)
        
        # TODO: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥
        test_cases = [
            "í•œêµ­ì˜ ìˆ˜ë„ê°€ ì–´ë””ì•¼?",
            "í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ ì„¤ëª…í•´ë´",
            "íŒŒì´ì¬ ì½”ë“œ ì§œì¤˜",
            "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?",
            "ë§›ìˆëŠ” ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ ì•Œë ¤ì¤˜"
        ]
        
        results = []
        for i, question in enumerate(test_cases, 1):
            print(f"\n[{i}] ì§ˆë¬¸ (ë°˜ë§): {question}")
            
            response = self.generate(question, max_tokens=200)
            
            print(f"    ë‹µë³€: {response[:150]}{'...' if len(response) > 150 else ''}")
            
            # ì¡´ëŒ“ë§ ì²´í¬ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            jondaemal_markers = ['ìŠµë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 'ì„¸ìš”', 'í•´ìš”', 'ìš”.', 'ìš”!', 'ë‹ˆë‹¤', 'ì‹­ì‹œì˜¤']
            has_jondaemal = any(marker in response for marker in jondaemal_markers)
            
            print(f"    ì¡´ëŒ“ë§ ì‚¬ìš©: {'âœ… YES' if has_jondaemal else 'âŒ NO'}")
            
            results.append({
                "question": question,
                "response": response,
                "has_jondaemal": has_jondaemal
            })
        
        success_rate = sum(1 for r in results if r['has_jondaemal']) / len(results) * 100
        print(f"\nâœ… ì¡´ëŒ“ë§ ì‚¬ìš©ë¥ : {success_rate:.0f}% ({sum(1 for r in results if r['has_jondaemal'])}/{len(results)})")
        
        return results
    
    def test_general_qa(self):
        """ì¼ë°˜ QA í…ŒìŠ¤íŠ¸"""
        print("\n\nğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸")
        print("-" * 80)
        
        # TODO: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥
        test_cases = [
            {
                "question": "ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?",
                "keywords": ["ì¸ê³µì§€ëŠ¥", "AI", "í•™ìŠµ", "ì»´í“¨í„°"]
            },
            {
                "question": "ë¹„íŠ¸ì½”ì¸ ì„¤ëª…í•´ì¤˜",
                "keywords": ["ì•”í˜¸í™”í", "ë¸”ë¡ì²´ì¸", "ë””ì§€í„¸"]
            },
            {
                "question": "ê´‘í•©ì„±ì´ ë­ì•¼?",
                "keywords": ["ì‹ë¬¼", "ë¹›", "ì—ë„ˆì§€", "ì‚°ì†Œ"]
            },
            {
                "question": "WMSê°€ ë­ì•¼?",
                "keywords": ["WMS", "ë„ì…", "ë¹„ìš©", "ROI"]
            },
            {
                "question": "WMSê°€ ë­ì•¼?",
                "keywords": ["WMS", "ë„ì…", "ë¹„ìš©", "ROI"]
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases, 1):
            question = case['question']
            keywords = case['keywords']
            
            print(f"\n[{i}] ì§ˆë¬¸: {question}")
            
            response = self.generate(question, max_tokens=250)
            
            print(f"    ë‹µë³€: {response[:200]}{'...' if len(response) > 200 else ''}")
            
            # í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ ì²´í¬
            keyword_found = [kw for kw in keywords if kw.lower() in response.lower()]
            
            print(f"    ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(keyword_found) if keyword_found else 'ì—†ìŒ'}")
            
            results.append({
                "question": question,
                "response": response,
                "keywords_found": keyword_found,
                "relevance_score": len(keyword_found) / len(keywords)
            })
        
        avg_relevance = sum(r['relevance_score'] for r in results) / len(results) * 100
        print(f"\nâœ… í‰ê·  ê´€ë ¨ì„±: {avg_relevance:.0f}%")
        
        return results
    
    def test_instruction_following(self):
        """ì§€ì‹œ ë”°ë¥´ê¸° í…ŒìŠ¤íŠ¸"""
        print("\n\nğŸ“ í…ŒìŠ¤íŠ¸ 3: ì§€ì‹œ ì‚¬í•­ ì´í–‰")
        print("-" * 80)
        
        # TODO: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥
        test_cases = [
            {
                "question": "3ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ ì—­ì‚¬ë¥¼ ìš”ì•½í•´ì¤˜",
                "check": "sentence_count",
                "target": 3
            },
            {
                "question": "5ê°œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ë‚˜ì—´í•´ì¤˜",
                "check": "list_items",
                "keywords": ["Python", "Java", "JavaScript", "C", "C++", "Go", "Rust", "Ruby"]
            },
            {
                "question": "ê°„ë‹¨í•˜ê²Œ í•œ ì¤„ë¡œ ì„¤ëª…í•´ì¤˜: ë¨¸ì‹ ëŸ¬ë‹ì´ë€?",
                "check": "length",
                "max_length": 100
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases, 1):
            question = case['question']
            check_type = case['check']
            
            print(f"\n[{i}] ì§ˆë¬¸: {question}")
            
            response = self.generate(question, max_tokens=200)
            
            print(f"    ë‹µë³€: {response}")
            
            # ê²€ì¦
            passed = False
            if check_type == "sentence_count":
                sentence_count = response.count('.') + response.count('!') + response.count('?')
                passed = abs(sentence_count - case['target']) <= 2
                print(f"    ë¬¸ì¥ ìˆ˜: {sentence_count} (ëª©í‘œ: {case['target']}) - {'âœ…' if passed else 'âŒ'}")
            
            elif check_type == "list_items":
                items_found = [kw for kw in case['keywords'] if kw in response]
                passed = len(items_found) >= 3
                print(f"    í•­ëª© ë°œê²¬: {len(items_found)}ê°œ ({', '.join(items_found[:5])}) - {'âœ…' if passed else 'âŒ'}")
            
            elif check_type == "length":
                length = len(response)
                passed = length <= case['max_length']
                print(f"    ê¸¸ì´: {length}ì (ìµœëŒ€: {case['max_length']}ì) - {'âœ…' if passed else 'âŒ'}")
            
            results.append({
                "question": question,
                "response": response,
                "passed": passed
            })
        
        success_rate = sum(1 for r in results if r['passed']) / len(results) * 100
        print(f"\nâœ… ì§€ì‹œ ì´í–‰ë¥ : {success_rate:.0f}% ({sum(1 for r in results if r['passed'])}/{len(results)})")
        
        return results
    
    def test_creative_tasks(self):
        """ì°½ì˜ì  ì‘ì—… í…ŒìŠ¤íŠ¸"""
        print("\n\nğŸ“ í…ŒìŠ¤íŠ¸ 4: ì°½ì˜ì  ì‘ì—…")
        print("-" * 80)
        
        # TODO: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥
        test_cases = [
            "ì§§ì€ ì‹œ í•˜ë‚˜ ì¨ì¤˜",
            "ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì¤˜",
            "ê°„ë‹¨í•œ Python í•¨ìˆ˜ ì˜ˆì œ ë³´ì—¬ì¤˜"
        ]
        
        results = []
        for i, question in enumerate(test_cases, 1):
            print(f"\n[{i}] ì§ˆë¬¸: {question}")
            
            response = self.generate(question, max_tokens=250, temperature=0.8)
            
            print(f"    ë‹µë³€: {response}")
            
            # ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì‹¤íŒ¨)
            is_substantial = len(response) > 20
            print(f"    í’ˆì§ˆ: {'âœ… ì¶©ë¶„í•¨' if is_substantial else 'âŒ ë„ˆë¬´ ì§§ìŒ'}")
            
            results.append({
                "question": question,
                "response": response,
                "is_substantial": is_substantial
            })
        
        return results
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        all_results = {}
        
        # í…ŒìŠ¤íŠ¸ 1: ë°˜ë§â†’ì¡´ëŒ“ë§
        all_results['banmal_to_jondaemal'] = self.test_banmal_to_jondaemal()
        
        # í…ŒìŠ¤íŠ¸ 2: ì¼ë°˜ QA
        all_results['general_qa'] = self.test_general_qa()
        
        # í…ŒìŠ¤íŠ¸ 3: ì§€ì‹œ ë”°ë¥´ê¸°
        all_results['instruction_following'] = self.test_instruction_following()
        
        # í…ŒìŠ¤íŠ¸ 4: ì°½ì˜ì  ì‘ì—…
        all_results['creative_tasks'] = self.test_creative_tasks()
        
        # ìš”ì•½
        self.print_summary(all_results)
        
        return all_results
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
    def print_summary(self, results):
        print("\n\n" + "="*80)
        print(" ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        # ë°˜ë§â†’ì¡´ëŒ“ë§
        jondaemal_rate = sum(1 for r in results['banmal_to_jondaemal'] if r['has_jondaemal']) / len(results['banmal_to_jondaemal']) * 100
        print(f"\n1. ë°˜ë§â†’ì¡´ëŒ“ë§ ë³€í™˜: {jondaemal_rate:.0f}%")
        
        # ì¼ë°˜ QA
        qa_relevance = sum(r['relevance_score'] for r in results['general_qa']) / len(results['general_qa']) * 100
        print(f"2. ì¼ë°˜ QA ê´€ë ¨ì„±: {qa_relevance:.0f}%")
        
        # ì§€ì‹œ ë”°ë¥´ê¸°
        instruction_rate = sum(1 for r in results['instruction_following'] if r['passed']) / len(results['instruction_following']) * 100
        print(f"3. ì§€ì‹œ ì‚¬í•­ ì´í–‰: {instruction_rate:.0f}%")
        
        # ì°½ì˜ì  ì‘ì—…
        creative_rate = sum(1 for r in results['creative_tasks'] if r['is_substantial']) / len(results['creative_tasks']) * 100
        print(f"4. ì°½ì˜ì  ì‘ì—…: {creative_rate:.0f}%")
        
        # ì „ì²´ í‰ê· 
        overall = (jondaemal_rate + qa_relevance + instruction_rate + creative_rate) / 4
        print(f"\nâœ¨ ì „ì²´ í‰ê·  ì ìˆ˜: {overall:.1f}%")
        
        print("\n" + "="*80)
        print(f"í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80 + "\n")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="EEVE Checkpoint ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    # TODO: ê¸°ë³¸ ê²½ë¡œ í™•ì¸
    parser.add_argument(
        "--checkpoint",
        type=str,
        default="/home/work/eeve-korean-output/checkpoint-500",
        help="ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "--base-model",
        type=str,
        default="yanolja/EEVE-Korean-Instruct-10.8B-v1.0",
        help="ë² ì´ìŠ¤ ëª¨ë¸ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "--test",
        type=str,
        choices=['all', 'banmal', 'qa', 'instruction', 'creative'],
        default='all',
        help="ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ (ê¸°ë³¸: all)"
    )
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = CheckpointTester(
        base_model_path=args.base_model,
        checkpoint_path=args.checkpoint
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if args.test == 'all':
        results = tester.run_all_tests()
    elif args.test == 'banmal':
        results = tester.test_banmal_to_jondaemal()
    elif args.test == 'qa':
        results = tester.test_general_qa()
    elif args.test == 'instruction':
        results = tester.test_instruction_following()
    elif args.test == 'creative':
        results = tester.test_creative_tasks()
    
    # ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
    output_file = f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_file}")


if __name__ == "__main__":
    main()

